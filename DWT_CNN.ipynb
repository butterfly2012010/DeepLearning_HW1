{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# For feature extraction: discrete wavelet transform\n",
    "import pywt\n",
    "\n",
    "# For CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train.txt\") as f:\n",
    "    train_file_list = f.readlines()\n",
    "with open(\"./val.txt\") as f:\n",
    "    val_file_list = f.readlines()\n",
    "with open(\"./test.txt\") as f:\n",
    "    test_file_list = f.readlines()\n",
    "\n",
    "train_file_list = [x.strip().split(sep=\" \") for x in train_file_list]\n",
    "val_file_list = [x.strip().split(sep=\" \") for x in val_file_list]\n",
    "test_file_list = [x.strip().split(sep=\" \") for x in test_file_list]\n",
    "\n",
    "train_label = [int(x[1]) for x in train_file_list]\n",
    "val_label = [int(x[1]) for x in val_file_list]\n",
    "test_label = [int(x[1]) for x in test_file_list]\n",
    "\n",
    "train_file_list = [x[0] for x in train_file_list]\n",
    "val_file_list = [x[0] for x in val_file_list]\n",
    "test_file_list = [x[0] for x in test_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cpus:  64\n"
     ]
    }
   ],
   "source": [
    "print(\"# cpus: \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadImage(filePath):\n",
    "    # image = cv2.imread(filePath, cv2.IMREAD_COLOR)\n",
    "    image = cv2.imread(filePath, cv2.IMREAD_GRAYSCALE)\n",
    "    # image = cv2.resize(image, (256, 256))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:18<00:00, 3495.71it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 232328.51it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 474349.54it/s]\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    train_imgs = pool.map(ReadImage, tqdm(train_file_list))\n",
    "    val_imgs = pool.map(ReadImage, tqdm(val_file_list))\n",
    "    test_imgs = pool.map(ReadImage, tqdm(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the images to 256x256\n",
    "def ResizeImage(image):\n",
    "    # resized_img = cv2.resize(image, (256, 256))\n",
    "    resized_img = cv2.resize(image, (128, 128))\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:24<00:00, 2585.92it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 4657.13it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 4899.30it/s]\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    resized_train_imgs = pool.map(ResizeImage, tqdm(train_imgs))\n",
    "    resized_val_imgs = pool.map(ResizeImage, tqdm(val_imgs))\n",
    "    resized_test_imgs = pool.map(ResizeImage, tqdm(test_imgs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete Wavelet Transform\n",
    "def WaveletTransform(image):\n",
    "    coeffs = pywt.dwt2(data=image, wavelet='haar', mode='symmetric', axes=(0, 1))\n",
    "    # cA, (cH, cV, cD) = coeffs\n",
    "    # _, (cH, cV, cD) = coeffs\n",
    "    # cA, _ = coeffs\n",
    "    # _, (cH, cV, _) = coeffs\n",
    "    _, (cH, _, _) = coeffs\n",
    "    return np.array([cH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:07<00:00, 8090.36it/s] \n",
      "100%|██████████| 450/450 [00:00<00:00, 4965.20it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 12869.30it/s]\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool(processes=NUM_PROCESSES) as pool:\n",
    "    train_features = pool.map(WaveletTransform, tqdm(resized_train_imgs))\n",
    "    val_features = pool.map(WaveletTransform, tqdm(resized_val_imgs))\n",
    "    test_features = pool.map(WaveletTransform, tqdm(resized_test_imgs))\n",
    "\n",
    "# train_features = np.array(train_features).squeeze()\n",
    "# val_features = np.array(val_features).squeeze()\n",
    "# test_features = np.array(test_features).squeeze()\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "val_features = np.array(val_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63325, 1, 64, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        # 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,\n",
    "                                  stride=2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(num_features=16)\n",
    "        # 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,\n",
    "                                  stride=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(num_features=32)\n",
    "        # 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2,\n",
    "                                  stride=2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(num_features=64)\n",
    "        # 4\n",
    "        self.fc1 = nn.Linear(in_features=64,\n",
    "                              out_features=128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=128,\n",
    "                              out_features=50)\n",
    "        \n",
    "    def forward(x):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
